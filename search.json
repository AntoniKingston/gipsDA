[{"path":"https://AntoniKingston.github.io/gipsDA/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Antoni Zbigniew Kingston. Author. Norbert Maksymilian Frydrysiak. Author, maintainer. Adam Przemysław Chojecki. Contributor.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kingston AZ, Frydrysiak NM (2026). gipsDA: Training DA Models Utilizing gips. R package version 0.1.","code":"@Manual{,   title = {gipsDA: Training DA Models Utilizing gips},   author = {Antoni Zbigniew Kingston and Norbert Maksymilian Frydrysiak},   year = {2026},   note = {R package version 0.1}, }"},{"path":"https://AntoniKingston.github.io/gipsDA/index.html","id":"gipsda","dir":"","previous_headings":"","what":"Training DA Models Utilizing gips","title":"Training DA Models Utilizing gips","text":"R package discriminant analysis classification using covariance matrices permutation symmetries.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/index.html","id":"about-the-project","dir":"","previous_headings":"","what":"About The Project","title":"Training DA Models Utilizing gips","text":"gipsDA R package extends classical Linear Discriminant Analysis (LDA) Quadratic Discriminant Analysis (QDA) incorporating permutation group structures estimation covariance matrices. leveraging methodology gips library, package aims improve classification performance scenarios features (variables) exhibit underlying symmetries. core idea find impose permutation symmetry covariance matrix, acts form regularization can lead stable interpretable models, especially high-dimensional settings. ultimate goal submit gipsDA Comprehensive R Archive Network (CRAN).","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/index.html","id":"key-features","dir":"","previous_headings":"About The Project","what":"Key Features","title":"Training DA Models Utilizing gips","text":"Implementation four novel gips-based discriminant analysis classifiers. flexible, user-friendly model API consistent established machine learning libraries R. specialized gipsmult module modeling class-specific covariances shared symmetry. Designed following best practices R package development.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/index.html","id":"r-package-structure","dir":"","previous_headings":"","what":"R Package Structure","title":"Training DA Models Utilizing gips","text":"adopt best practices R package development, repository organized following standard structure: gipsmult_: files belonging gipsmult module. models_: files belonging models module. tests/ directory houses testing scripts ensure reliability correctness package. Automated unit tests implemented using testthat framework designed verify functionality individual functions methods within modules.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/index.html","id":"available-models-in-gipsda","dir":"","previous_headings":"","what":"Available Models in gipsDA","title":"Training DA Models Utilizing gips","text":"gipsDA object can configured run one four different classification algorithms, different assumptions data structure. gipsLDA_weighted_average approach, separate covariance matrix first estimated class. final, single covariance matrix computed weighted average individual matrices. pooled matrix processed gips library used classification. gipsLDA_classic model follows traditional approach using classic pooled covariance estimator standard traditional LDA. single, pooled matrix processed gips library find probable permutation symmetry. gipsMultQDA model leverages gipsmult module. process involves first identifying single probable permutation structure common across classes. Subsequently, separate covariance matrix estimated class, matrix projected onto shared permutation. gipsQDA represents flexible model. gips library applied independently class. Consequently, class can uniquely estimated permutation structure distinct covariance matrix. analogous classic QDA framework individualized symmetry discovery class.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/find_MAP.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the Maximum A Posteriori Estimation — find_MAP","title":"Find the Maximum A Posteriori Estimation — find_MAP","text":"Use one optimization algorithms find permutation maximizes posteriori probability based observed data. optimization algorithms always find MAP, try find significant value. information can found \"Possible algorithms use optimizers\" section .","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/find_MAP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the Maximum A Posteriori Estimation — find_MAP","text":"","code":"find_MAP(   g,   max_iter = NA,   optimizer = NA,   show_progress_bar = TRUE,   save_all_perms = FALSE,   return_probabilities = FALSE )"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/find_MAP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the Maximum A Posteriori Estimation — find_MAP","text":"g Object gipsmult class. max_iter number iterations algorithm perform. least 2. optimizer = \"BF\", used; optimizer = \"MH\", finite; optimizer = \"HC\", can infinite. optimizer optimizer search maximum posteriori: \"BF\" (default unoptimized g perm size <= 9) - Brute Force; \"MH\" (default unoptimized g perm size > 10) - Metropolis-Hastings; \"HC\" - Hill Climbing; \"continue\" (default optimized g) - g optimized (see Examples). See Possible algorithms use optimizers section details. show_progress_bar boolean. Indicate whether show progress bar: max_iter infinite, show_progress_bar FALSE; return_probabilities = TRUE, shows additional progress bar time probabilities calculated. save_all_perms boolean. TRUE indicates saving list permutations visited optimization. can useful sometimes needs lot RAM. return_probabilities boolean. TRUE can provided save_all_perms = TRUE. : optimizer = \"MH\" - use Metropolis-Hastings results estimate posterior probabilities; optimizer = \"BF\" - use brute force results calculate exact posterior probabilities. additional calculations costly, second third progress bar shown (show_progress_bar = TRUE). examine probabilities optimization, call get_probabilities_from_gipsmult().","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/find_MAP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the Maximum A Posteriori Estimation — find_MAP","text":"Returns optimized object gipsmult class.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/find_MAP.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find the Maximum A Posteriori Estimation — find_MAP","text":"find_MAP() can produce warning : optimizer \"hill_climbing\" gets end max_iter without converging. optimizer find permutation smaller n0 number_of_observations","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/find_MAP.html","id":"possible-algorithms-to-use-as-optimizers","dir":"Reference","previous_headings":"","what":"Possible algorithms to use as optimizers","title":"Find the Maximum A Posteriori Estimation — find_MAP","text":"-depth explanation, see vignette(\"Optimizers\", package = \"gips\") pkgdown page. every algorithm, aliases available. \"brute_force\", \"BF\", \"full\" - use Brute Force algorithm checks whole permutation space given size. algorithm find actual Maximum Posteriori Estimation, computationally expensive bigger spaces. recommend Brute Force p <= 9. \"Metropolis_Hastings\", \"MH\" - use Metropolis-Hastings algorithm; see Wikipedia. algorithm draw random transposition every iteration consider changing current state (permutation). max_iter reached, algorithm return best permutation calculated MAP Estimator. implements Second approach references, section 4.1.2. algorithm used context special case Simulated Annealing user may familiar ; see Wikipedia. \"hill_climbing\", \"HC\" - use hill climbing algorithm; see Wikipedia. algorithm check transpositions every iteration go one biggest posteriori value. optimization ends neighbors smaller posteriori value. max_iter reached end, warning shown, recommended continue optimization output find_MAP() optimizer = \"continue\"; see examples. Remember p*(p-1)/2 transpositions checked every iteration. bigger p, may costly.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/find_MAP.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Find the Maximum A Posteriori Estimation — find_MAP","text":"Piotr Graczyk, Hideyuki Ishi, Bartosz Kołodziejek, Hélène Massam. \"Model selection space Gaussian models invariant symmetry.\" Annals Statistics, 50(3) 1747-1774 June 2022. arXiv link; doi:10.1214/22-AOS2174","code":""},{"path":[]},{"path":"https://AntoniKingston.github.io/gipsDA/reference/find_MAP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the Maximum A Posteriori Estimation — find_MAP","text":"","code":"require(\"MASS\") # for mvrnorm() #> Loading required package: MASS  perm_size <- 6 mu1 <- runif(6, -10, 10) mu2 <- runif(6, -10, 10) # Assume we don't know the means sigma1 <- matrix(   data = c(     1.0, 0.8, 0.6, 0.4, 0.6, 0.8,     0.8, 1.0, 0.8, 0.6, 0.4, 0.6,     0.6, 0.8, 1.0, 0.8, 0.6, 0.4,     0.4, 0.6, 0.8, 1.0, 0.8, 0.6,     0.6, 0.4, 0.6, 0.8, 1.0, 0.8,     0.8, 0.6, 0.4, 0.6, 0.8, 1.0   ),   nrow = perm_size, byrow = TRUE ) sigma2 <- matrix(   data = c(     1.0, 0.5, 0.2, 0.0, 0.2, 0.5,     0.5, 1.0, 0.5, 0.2, 0.0, 0.2,     0.2, 0.5, 1.0, 0.5, 0.2, 0.0,     0.0, 0.2, 0.5, 1.0, 0.5, 0.2,     0.2, 0.0, 0.2, 0.5, 1.0, 0.5,     0.5, 0.2, 0.0, 0.2, 0.5, 1.0   ),   nrow = perm_size, byrow = TRUE ) # sigma1 and sigma2 are matrices invariant under permutation (1,2,3,4,5,6) numbers_of_observations <- c(21,37) Z1 <- MASS::mvrnorm(numbers_of_observations[1], mu = mu1, Sigma = sigma1) Z2 <- MASS::mvrnorm(numbers_of_observations[2], mu = mu2, Sigma = sigma2) S1 <- cov(Z1) S2 <- cov(Z2) # Assume we have to estimate the mean  g <- gipsmult(list(S1,S2), numbers_of_observations)  g_map <- find_MAP(g, max_iter = 5, show_progress_bar = FALSE, optimizer = \"Metropolis_Hastings\") g_map #> The permutation (): #>  - was found after 5 posteriori calculations; #>  - is 1 times more likely than the () permutation.  g_map2 <- find_MAP(g_map, max_iter = 5, show_progress_bar = FALSE, optimizer = \"continue\")  if (require(\"graphics\")) {   plot(g_map2, type = \"both\", logarithmic_x = TRUE) }   g_map_BF <- find_MAP(g, show_progress_bar = FALSE, optimizer = \"brute_force\")"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/get_probabilities_from_gipsmult.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract probabilities for gipsmult object optimized with return_probabilities = TRUE — get_probabilities_from_gipsmult","title":"Extract probabilities for gipsmult object optimized with return_probabilities = TRUE — get_probabilities_from_gipsmult","text":"gipsmult object optimized find_MAP(return_probabilities = TRUE) function, calculated probabilities can extracted function.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/get_probabilities_from_gipsmult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract probabilities for gipsmult object optimized with return_probabilities = TRUE — get_probabilities_from_gipsmult","text":"","code":"get_probabilities_from_gipsmult(g)"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/get_probabilities_from_gipsmult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract probabilities for gipsmult object optimized with return_probabilities = TRUE — get_probabilities_from_gipsmult","text":"g object class gipsmult. result find_MAP(return_probabilities = TRUE).","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/get_probabilities_from_gipsmult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract probabilities for gipsmult object optimized with return_probabilities = TRUE — get_probabilities_from_gipsmult","text":"Returns numeric vector, calculated values probabilities. Names contain permutations probabilities represent. gipsmult object optimized find_MAP(return_probabilities = FALSE), returns NULL object. sorted according probability.","code":""},{"path":[]},{"path":"https://AntoniKingston.github.io/gipsDA/reference/get_probabilities_from_gipsmult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract probabilities for gipsmult object optimized with return_probabilities = TRUE — get_probabilities_from_gipsmult","text":"","code":"Ss <- list(matrix(c(1, 0.5, 0.5, 2), nrow = 2, byrow = TRUE), matrix(c(2, 1, 3, 7), nrow = 2, byrow = TRUE)) noo <- c(10,13) g <- gipsmult(Ss, noo) g_map <- find_MAP(g,   optimizer = \"BF\", show_progress_bar = FALSE,   return_probabilities = TRUE, save_all_perms = TRUE )  get_probabilities_from_gipsmult(g_map) #>        ()     (1,2)  #> 0.6487995 0.3512005"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipslda.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Discriminant Analysis with gips Covariance Projection — gipslda","title":"Linear Discriminant Analysis with gips Covariance Projection — gipslda","text":"modification Linear Discriminant Analysis (LDA) within-class covariance matrix projected onto permutation-invariant structure using gips framework.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipslda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Discriminant Analysis with gips Covariance Projection — gipslda","text":"","code":"gipslda(x, ...)  # S3 method for class 'formula' gipslda(formula, data, ..., subset, na.action)  # Default S3 method gipslda(x, grouping, prior = proportions,   tol = 1e-4, nu = 5, weighted_avg = FALSE,   MAP = TRUE, optimizer = NULL, max_iter = NULL, ...)  # S3 method for class 'data.frame' gipslda(x, ...)  # S3 method for class 'matrix' gipslda(x, grouping, ..., subset, na.action)"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipslda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Discriminant Analysis with gips Covariance Projection — gipslda","text":"x (required formula given principal argument) matrix data frame Matrix containing explanatory variables. ... Arguments passed methods. formula formula form groups ~ x1 + x2 + .... response grouping factor right-hand side specifies (non-factor) discriminators. data optional data frame, list environment variables specified formula preferentially taken. grouping (required formula principal argument given) factor specifying class observation. prior prior probabilities class membership. unspecified, class proportions training set used. tol tolerance decide matrix singular; variables whose variance less tol^2 rejected. subset index vector specifying cases used training sample. (NOTE: must named.) na.action function specifying action NAs. #' @param weighted_avg Logical; TRUE, uses weighted average class-specific covariance matrices instead pooled covariance. MAP Logical; whether compute Maximum Posteriori gips projection covariance matrix. optimizer Character; optimization method used gips (e.g. \"BF\" \"MH\"). max_iter Maximum number iterations optimizer.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipslda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Discriminant Analysis with gips Covariance Projection — gipslda","text":"object class \"gipslda\" containing: prior: prior class probabilities counts: number observations per class means: group means scaling: linear discriminant coefficients svd: singular values -class scatter N: number observations optimization_info: information gips optimization call: matched call","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipslda.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear Discriminant Analysis with gips Covariance Projection — gipslda","text":"Unlike classical LDA, within-class covariance matrix first projected onto permutation-invariant structure using gips framework. can stabilize covariance estimation high dimensions symmetry assumptions justified. choice optimizer MAP estimation affects covariance estimate resulting discriminant directions. See Chojecki et al. (2025) theoretical background.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipslda.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Linear Discriminant Analysis with gips Covariance Projection — gipslda","text":"function inspired lda drop-replacement. covariance estimator, optimization procedure, returned object differ substantially.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipslda.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear Discriminant Analysis with gips Covariance Projection — gipslda","text":"Chojecki, ., et al. (2025). Learning Permutation Symmetry Gaussian Vector gips R. Journal Statistical Software, 112(7), 1–38. doi:10.18637/jss.v112.i07","code":""},{"path":[]},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipslda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear Discriminant Analysis with gips Covariance Projection — gipslda","text":"","code":"Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),                    Sp = rep(c(\"s\",\"c\",\"v\"), rep(50,3))) train <- sample(1:150, 75) z <- gipslda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train) predict(z, Iris[-train, ])$class #>  [1] s s s s s s s s s s s s s s s s s s s s s s s s s c c c c c c c c c c c c c #> [39] c c c v c c c c c c v v v v v v v v v v v v v v v c v v v v v v v v v v v #> Levels: c s v (z1 <- update(z, . ~ . - Petal.W.)) #> Call: #> gipslda(Sp ~ Sepal.L. + Sepal.W. + Petal.L., data = Iris, prior = c(1,  #>     1, 1)/3, subset = train) #>  #> Prior probabilities of groups: #>         c         s         v  #> 0.3333333 0.3333333 0.3333333  #>  #> Group means: #>   Sepal.L. Sepal.W. Petal.L. #> c 5.885185 2.766667 4.166667 #> s 5.020000 3.476000 1.452000 #> v 6.630435 2.952174 5.508696 #>  #> Coefficients of linear discriminants: #>                 LD1       LD2 #> Sepal.L.  0.5096716 -1.145938 #> Sepal.W.  1.0822205  3.458572 #> Petal.L. -2.5577491  0.969699 #>  #> Proportion of trace: #>    LD1    LD2  #> 0.9884 0.0116  #>  #> Permutations with their estimated probabilities: #> [1] (23)"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmult.html","id":null,"dir":"Reference","previous_headings":"","what":"The constructor of a gipsmult class. — gipsmult","title":"The constructor of a gipsmult class. — gipsmult","text":"Create gipsmult object. object contain initial data information needed find likely invariant permutation. perform optimization. One must call find_MAP() function . See examples .","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The constructor of a gipsmult class. — gipsmult","text":"","code":"gipsmult(   Ss,   numbers_of_observations,   delta = 3,   D_matrices = NULL,   was_mean_estimated = TRUE,   perm = \"\" )  new_gipsmult(   list_of_gips_perm,   Ss,   numbers_of_observations,   delta,   D_matrices,   was_mean_estimated,   optimization_info )"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The constructor of a gipsmult class. — gipsmult","text":"delta number, hyper-parameter Bayesian model. strictly bigger 1. See Hyperparameters section . was_mean_estimated boolean. Set TRUE (default) S parameter result stats::cov() function. Set FALSE S parameter result (t(Z) %*% Z) / number_of_observations calculation. perm optional permutation base gipsmult object. can gips_perm permutation class, anything function permutations::permutation() can handle. can also gipsmult class, interpreted underlying gips_perm. list_of_gips_perm list single element gips_perm class. base object gipsmult object. optimization_info internal use . NULL list information optimization process. S matrix; empirical covariance matrix. Z observed data: one know theoretical mean estimate observed mean, use S = cov(Z), leave parameter was_mean_estimated = TRUE default; one know theoretical mean 0, use S = (t(Z) %*% Z) / number_of_observations, set parameter was_mean_estimated = FALSE. number_of_observations number data points S based . D_matrix Symmetric, positive-definite matrix size S. Hyper-parameter Bayesian model. NULL, (hopefully) reasonable one derived data. details, see Hyperparameters section .","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The constructor of a gipsmult class. — gipsmult","text":"gipsmult() returns object gipsmult class safety checks. new_gipsmult() returns object gipsmult class without safety checks.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmult.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"The constructor of a gipsmult class. — gipsmult","text":"new_gipsmult(): Constructor. intended low-level use.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmult.html","id":"methods-for-a-gipsmult-class","dir":"Reference","previous_headings":"","what":"Methods for a gipsmult class","title":"The constructor of a gipsmult class. — gipsmult","text":"plot.gipsmult() print.gipsmult()","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmult.html","id":"hyperparameters","dir":"Reference","previous_headings":"","what":"Hyperparameters","title":"The constructor of a gipsmult class. — gipsmult","text":"encourage user try D_matrix = d * , identity matrix size p x p d > 0 different d. d small compared data (e.g., d = 0.1 * mean(diag(S))), bigger structures found. d big compared data (e.g., d = 100 * mean(diag(S))), posterior distribution depend data. Taking D_matrix = d * equivalent setting S <- S / d. default D_matrix D_matrix = d * , d = mean(diag(S)), equivalent modifying S mean value diagonal 1. Bayesian model, prior distribution covariance matrix generalized case Wishart distribution.","code":""},{"path":[]},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The constructor of a gipsmult class. — gipsmult","text":"","code":"perm_size <- 5 numbers_of_observations <- c(15, 18, 19) Sigma <- diag(rep(1, perm_size)) n_matrices <- 3 df <- 20 Ss <- rWishart(n = n_matrices, df = df, Sigma = Sigma) Ss <- lapply(1:n_matrices, function(x) Ss[, , x]) g <- gipsmult(Ss, numbers_of_observations)  g_map <- find_MAP(g, show_progress_bar = FALSE, optimizer = \"brute_force\") g_map #> The permutation (1,2,5,3,4): #>  - was found after 67 posteriori calculations; #>  - is 1.132e+22 times more likely than the () permutation.  print(g_map) #> The permutation (1,2,5,3,4): #>  - was found after 67 posteriori calculations; #>  - is 1.132e+22 times more likely than the () permutation.  if (require(\"graphics\")) {   plot(g_map, type = \"MLE\", logarithmic_x = TRUE) }"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmultqda.html","id":null,"dir":"Reference","previous_headings":"","what":"Quadratic Discriminant Analysis with multiple gips-projected covariances — gipsmultqda","title":"Quadratic Discriminant Analysis with multiple gips-projected covariances — gipsmultqda","text":"Quadratic Discriminant Analysis (QDA) class covariance matrix projected using gipsmult framework, allowing structured permutation symmetry across multiple covariance matrices.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmultqda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quadratic Discriminant Analysis with multiple gips-projected covariances — gipsmultqda","text":"","code":"gipsmultqda(x, ...)  # S3 method for class 'formula' gipsmultqda(formula, data, ..., subset, na.action)  # Default S3 method gipsmultqda(x, grouping, prior = proportions,   nu = 5, MAP = TRUE, optimizer = NULL, max_iter = NULL, ...)  # S3 method for class 'data.frame' gipsmultqda(x, ...)  # S3 method for class 'matrix' gipsmultqda(x, grouping, ..., subset, na.action)"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmultqda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quadratic Discriminant Analysis with multiple gips-projected covariances — gipsmultqda","text":"x (required formula given principal argument) matrix data frame containing explanatory variables. ... Arguments passed methods. formula formula form groups ~ x1 + x2 + .... response grouping factor right-hand side specifies (non-factor) discriminators. data optional data frame, list environment variables specified formula preferentially taken. grouping factor specifying class observation. prior Prior probabilities class membership. Must sum one. nu Degrees freedom parameter used internally covariance projection. MAP Logical; TRUE, maximum posteriori covariance projection used. optimizer Character string specifying optimization method used covariance projection. NULL, default choice made based problem dimension. max_iter Maximum number iterations stochastic optimizers. subset index vector specifying cases used training sample. (NOTE: must named.) na.action function specifying action taken NAs found.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmultqda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quadratic Discriminant Analysis with multiple gips-projected covariances — gipsmultqda","text":"object class \"gipsmultqda\" containing: prior: prior probabilities groups counts: number observations per group means: group means scaling: array group-specific scaling matrices derived projected covariance matrices ldet: log-determinants projected covariance matrices lev: class labels N: total number observations optimization_info: information returned covariance projection optimizer call: matched call","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmultqda.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quadratic Discriminant Analysis with multiple gips-projected covariances — gipsmultqda","text":"function modification qda class-specific covariance matrices jointly projected improve numerical stability exploit shared symmetry assumptions. contrast classical QDA, estimates class covariance matrix independently, gipsmultqda performs joint projection class covariance matrices using gipsmult framework. allows incorporation shared permutation symmetries can improve classification performance high-dimensional small-sample regimes. Several classification rules available via predict.gipsmultqda, including plug-, predictive, debiased, leave-one-cross-validation.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmultqda.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Quadratic Discriminant Analysis with multiple gips-projected covariances — gipsmultqda","text":"function drop-replacement qda. covariance estimation, returned object, classification rules differ substantially. theoretical background details covariance projection documented gipsmult package.","code":""},{"path":[]},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsmultqda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quadratic Discriminant Analysis with multiple gips-projected covariances — gipsmultqda","text":"","code":"tr <- sample(1:50, 25) train <- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3]) test <- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3]) cl <- factor(c(rep(\"s\",25), rep(\"c\",25), rep(\"v\",25))) z <- gipsmultqda(train, cl) predict(z,test)$class #>  [1] s s s s s s s s s s s s s s s s s s s s s s s s s c c c c c c c c c c c c c #> [39] c c c c c c c c c c c c v v v v v v v v v v v v v v v v v v v v v v v v v #> Levels: c s v"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsqda.html","id":null,"dir":"Reference","previous_headings":"","what":"Quadratic Discriminant Analysis with gips covariance projection — gipsqda","title":"Quadratic Discriminant Analysis with gips covariance projection — gipsqda","text":"Quadratic discriminant analysis (QDA) using covariance matrices projected via gips framework enforce permutation symmetry improve numerical stability.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsqda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quadratic Discriminant Analysis with gips covariance projection — gipsqda","text":"","code":"gipsqda(x, ...)  # S3 method for class 'formula' gipsqda(formula, data, ..., subset, na.action)  # Default S3 method gipsqda(x, grouping, prior = proportions,   nu = 5, MAP = TRUE, optimizer = NULL, max_iter = NULL, ...)  # S3 method for class 'data.frame' gipsqda(x, ...)  # S3 method for class 'matrix' gipsqda(x, grouping, ..., subset, na.action)"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsqda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quadratic Discriminant Analysis with gips covariance projection — gipsqda","text":"x (required formula given principal argument) matrix data frame containing explanatory variables. ... Arguments passed methods. formula formula form groups ~ x1 + x2 + .... response grouping factor right-hand side specifies (non-factor) discriminators. data optional data frame, list environment variables specified formula preferentially taken. grouping (required formula given) factor specifying class observation. prior prior probabilities class membership. Must sum one length equal number groups. nu Degrees freedom parameter used internally covariance projection. MAP Logical; TRUE, maximum posteriori covariance projection used. optimizer Character string specifying optimization method used covariance projection. NULL, default choice depending problem dimension used. max_iter Maximum number iterations stochastic optimizers. subset index vector specifying cases used training sample. (NOTE: must named.) na.action function specifying action taken NAs found.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsqda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quadratic Discriminant Analysis with gips covariance projection — gipsqda","text":"object class \"gipsqda\" containing following components: prior: prior probabilities groups counts: number observations group means: group means scaling: group-specific scaling matrices derived projected covariance matrices ldet: log-determinants projected covariance matrices lev: class labels N: total number observations optimization_info: information returned covariance projection optimizer call: matched call","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsqda.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quadratic Discriminant Analysis with gips covariance projection — gipsqda","text":"function minor modification qda, replacing classical sample covariance estimators projected covariance matrices obtained using project_covs(). Quadratic discriminant analysis models class covariance matrix. gipsqda, covariance matrices projected using gips framework, enforces permutation symmetry mitigates singularity overfitting high-dimensional small-sample settings. Classification can performed using plug-, predictive, debiased, leave-one-cross-validation rules via predict.gipsqda.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsqda.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Quadratic Discriminant Analysis with gips covariance projection — gipsqda","text":"function may called either formula interface matrix grouping factor. Arguments subset na.action, used, must named.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsqda.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quadratic Discriminant Analysis with gips covariance projection — gipsqda","text":"Chojecki, ., et al. (2025). Learning Permutation Symmetry Gaussian Vector gips R. Journal Statistical Software, 112(7), 1–38. doi:10.18637/jss.v112.i07 Venables, W. N. Ripley, B. D. (2002). Modern Applied Statistics S. Fourth edition. Springer.","code":""},{"path":[]},{"path":"https://AntoniKingston.github.io/gipsDA/reference/gipsqda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quadratic Discriminant Analysis with gips covariance projection — gipsqda","text":"","code":"tr <- sample(1:50, 25) train <- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3]) test <- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3]) cl <- factor(c(rep(\"s\",25), rep(\"c\",25), rep(\"v\",25))) z <- gipsqda(train, cl) predict(z,test)$class #>  [1] s s s s s s s s s s s s s s s s s s s s s s s s s c c c c c c c c v c c c c #> [39] v c c c c c c c c c c c v v v v v v v v v v v v v v v v v v v v v v v v v #> Levels: c s v"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/log_posteriori_of_gipsmult.html","id":null,"dir":"Reference","previous_headings":"","what":"A log of a posteriori that the covariance matrix is invariant under permutation — log_posteriori_of_gipsmult","title":"A log of a posteriori that the covariance matrix is invariant under permutation — log_posteriori_of_gipsmult","text":"precisely, logarithm unnormalized posterior probability. goal function optimization algorithms find_MAP() function. perm_proposal maximizes function Maximum Posteriori (MAP) Estimator.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/log_posteriori_of_gipsmult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A log of a posteriori that the covariance matrix is invariant under permutation — log_posteriori_of_gipsmult","text":"","code":"log_posteriori_of_gipsmult(g)"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/log_posteriori_of_gipsmult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A log of a posteriori that the covariance matrix is invariant under permutation — log_posteriori_of_gipsmult","text":"g object gipsmult class.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/log_posteriori_of_gipsmult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A log of a posteriori that the covariance matrix is invariant under permutation — log_posteriori_of_gipsmult","text":"Returns value logarithm unnormalized Posteriori.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/log_posteriori_of_gipsmult.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A log of a posteriori that the covariance matrix is invariant under permutation — log_posteriori_of_gipsmult","text":"calculated using formulas (33) (27) references. Inf NaN reached, produces warning.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/log_posteriori_of_gipsmult.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A log of a posteriori that the covariance matrix is invariant under permutation — log_posteriori_of_gipsmult","text":"Piotr Graczyk, Hideyuki Ishi, Bartosz Kołodziejek, Hélène Massam. \"Model selection space Gaussian models invariant symmetry.\" Annals Statistics, 50(3) 1747-1774 June 2022. arXiv link; doi:10.1214/22-AOS2174","code":""},{"path":[]},{"path":"https://AntoniKingston.github.io/gipsDA/reference/log_posteriori_of_gipsmult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A log of a posteriori that the covariance matrix is invariant under permutation — log_posteriori_of_gipsmult","text":"","code":"# In the space with p = 2, there is only 2 permutations: perm1 <- permutations::as.cycle(\"(1)(2)\") perm2 <- permutations::as.cycle(\"(1,2)\") S1 <- matrix(c(1, 0.5, 0.5, 2), nrow = 2, byrow = TRUE) S2 <- matrix(c(2, 1, 3, 7), nrow = 2, byrow = TRUE) g1 <- gipsmult(list(S1,S2), c(100,100), perm = perm1) g2 <- gipsmult(list(S1,S2), c(100,100), perm = perm2) log_posteriori_of_gipsmult(g1) # -354.4394, this is the MAP Estimator #> [1] -354.4394 log_posteriori_of_gipsmult(g2) # -380.0079 #> [1] -380.0079  exp(log_posteriori_of_gipsmult(g1) - log_posteriori_of_gipsmult(g2)) # 127131902082 #> [1] 127131902082 # g1 is 127131902082 times more likely than g2. # This is the expected outcome because S1[1,1] and S2 [1,1] significantly differ from S1[2,2] and S2[2,2] respectively.  # ========================================================================  S3 <- matrix(c(1, 0.5, 0.5, 1.1), nrow = 2, byrow = TRUE) S4 <- matrix(c(2, 1, 3, 2.137), nrow = 2, byrow = TRUE) g1 <- gipsmult(list(S3,S4), c(100,100), perm = perm1) g2 <- gipsmult(list(S3,S4), c(100,100), perm = perm2) log_posteriori_of_gipsmult(g1) # -148.6485 #> Warning: ℹ `project_matrix()` is designed for positive semi-definite matrices #> ✖ You provided `S` that is not positive semi-definite matrix #> • `gips` can still project this matrix on the provided permutation #> ℹ Did You provide the wrong `S` matrix? #> [1] -148.6485 log_posteriori_of_gipsmult(g2) # -145.3019, this is the MAP Estimator #> Warning: ℹ `project_matrix()` is designed for positive semi-definite matrices #> ✖ You provided `S` that is not positive semi-definite matrix #> • `gips` can still project this matrix on the provided permutation #> ℹ Did You provide the wrong `S` matrix? #> [1] -145.3019  exp(log_posteriori_of_gipsmult(g2) - log_posteriori_of_gipsmult(g1)) # 28.406 #> Warning: ℹ `project_matrix()` is designed for positive semi-definite matrices #> ✖ You provided `S` that is not positive semi-definite matrix #> • `gips` can still project this matrix on the provided permutation #> ℹ Did You provide the wrong `S` matrix? #> Warning: ℹ `project_matrix()` is designed for positive semi-definite matrices #> ✖ You provided `S` that is not positive semi-definite matrix #> • `gips` can still project this matrix on the provided permutation #> ℹ Did You provide the wrong `S` matrix? #> [1] 28.406 # g2 is 28.406 times more likely than g1. # This is the expected outcome because S1[1,1] and S2 [1,1] are very close to S1[2,2] and S2[2,2] respectively."},{"path":"https://AntoniKingston.github.io/gipsDA/reference/plot.gipsmult.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot optimized matrix or optimization gipsmult object — plot.gipsmult","title":"Plot optimized matrix or optimization gipsmult object — plot.gipsmult","text":"Plot heatmaps MAP covariance matrices estimator convergence optimization method. plot depends type argument.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/plot.gipsmult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot optimized matrix or optimization gipsmult object — plot.gipsmult","text":"","code":"# S3 method for class 'gipsmult' plot(   x,   type = NA,   logarithmic_y = TRUE,   logarithmic_x = FALSE,   color = NULL,   title_text = \"Convergence plot\",   xlabel = NULL,   ylabel = NULL,   show_legend = TRUE,   ylim = NULL,   xlim = NULL,   ... )"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/plot.gipsmult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot optimized matrix or optimization gipsmult object — plot.gipsmult","text":"x Object gipsmult class. type character vector length 1. One c(\"heatmap\", \"MLE\", \"best\", \"\", \"\", \"n0\", \"block_heatmap\"): \"heatmap\", \"MLE\" - Plots heatmap Maximum Likelihood Estimator covariance matrix given permutation. , S matrix inside gipsmult object projected permutation gipsmult object. \"best\" - Plots line biggest posteriori found time. \"\" - Plots line posteriori visited states. \"\" - Plots lines \"\" \"best\". \"n0\" - Plots line n0s spotted optimization (\"MH\" optimization). \"block_heatmap\" - Plots heatmap diagonally block representation S. Non-block entries (equal 0) white better clarity. default value NA, changed \"heatmap\" non-optimized gipsmult objects \"\" optimized ones. Using default produces warning. arguments ignored type = \"heatmap\", type = \"MLE\", type = \"block_heatmap\". logarithmic_y, logarithmic_x boolean. Sets axis plot logarithmic scale. color Vector colors used plot lines. title_text Text title plot. xlabel Text bottom plot. ylabel Text left plot. show_legend boolean. Whether show legend. ylim Limits y axis. NULL, minimum, maximum log_posteriori_of_gipsmult() taken. xlim Limits x axis. NULL, whole optimization process shown. ... Additional arguments passed various elements plot.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/plot.gipsmult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot optimized matrix or optimization gipsmult object — plot.gipsmult","text":"type one \"best\", \"\", \"\" \"n0\", returns invisible NULL. type one \"heatmap\", \"MLE\" \"block_heatmap\", returns object class ggplot.","code":""},{"path":[]},{"path":"https://AntoniKingston.github.io/gipsDA/reference/plot.gipsmult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot optimized matrix or optimization gipsmult object — plot.gipsmult","text":"","code":"require(\"MASS\") # for mvrnorm()  perm_size <- 6 mu1 <- runif(6, -10, 10) mu2 <- runif(6, -10, 10) # Assume we don't know the means sigma1 <- matrix(   data = c(     1.0, 0.8, 0.6, 0.4, 0.6, 0.8,     0.8, 1.0, 0.8, 0.6, 0.4, 0.6,     0.6, 0.8, 1.0, 0.8, 0.6, 0.4,     0.4, 0.6, 0.8, 1.0, 0.8, 0.6,     0.6, 0.4, 0.6, 0.8, 1.0, 0.8,     0.8, 0.6, 0.4, 0.6, 0.8, 1.0   ),   nrow = perm_size, byrow = TRUE ) sigma2 <- matrix(   data = c(     1.0, 0.5, 0.2, 0.0, 0.2, 0.5,     0.5, 1.0, 0.5, 0.2, 0.0, 0.2,     0.2, 0.5, 1.0, 0.5, 0.2, 0.0,     0.0, 0.2, 0.5, 1.0, 0.5, 0.2,     0.2, 0.0, 0.2, 0.5, 1.0, 0.5,     0.5, 0.2, 0.0, 0.2, 0.5, 1.0   ),   nrow = perm_size, byrow = TRUE ) # sigma1 and sigma2 are matrices invariant under permutation (1,2,3,4,5,6) numbers_of_observations <- c(21,37) Z1 <- MASS::mvrnorm(numbers_of_observations[1], mu = mu1, Sigma = sigma1) Z2 <- MASS::mvrnorm(numbers_of_observations[2], mu = mu2, Sigma = sigma2) S1 <- cov(Z1) S2 <- cov(Z2) # Assume we have to estimate the mean  g <- gipsmult(list(S1,S2), numbers_of_observations) if (require(\"graphics\")) {   plot(g, type = \"MLE\") }   g_map <- find_MAP(g, max_iter = 30, show_progress_bar = FALSE, optimizer = \"hill_climbing\") if (require(\"graphics\")) {   plot(g_map, type = \"both\", logarithmic_x = TRUE) }   if (require(\"graphics\")) {   plot(g_map, type = \"MLE\") }  # Now, the output is (most likely) different because the permutation   # `g_map[[1]]` is (most likely) not an identity permutation.  g_map_MH <- find_MAP(g, max_iter = 30, show_progress_bar = FALSE, optimizer = \"MH\") if (require(\"graphics\")) {   plot(g_map_MH, type = \"n0\") }"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/print.gipsmult.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing gipsmult object — print.gipsmult","title":"Printing gipsmult object — print.gipsmult","text":"Printing function gipsmult class.","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/print.gipsmult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing gipsmult object — print.gipsmult","text":"","code":"# S3 method for class 'gipsmult' print(   x,   digits = 3,   compare_to_original = TRUE,   log_value = FALSE,   oneline = FALSE,   ... )"},{"path":"https://AntoniKingston.github.io/gipsDA/reference/print.gipsmult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing gipsmult object — print.gipsmult","text":"x object gipsmult class. digits number digits comma posteriori presented. can negative. default, Inf. passed base::round(). compare_to_original logical. Whether print many times likely current permutation compared : identity permutation () (unoptimized gipsmult object); starting permutation (optimized gipsmult object). log_value logical. Whether print logarithmic value. Default FALSE. oneline logical. Whether print one multiple lines. Default FALSE. ... additional arguments passed base::cat().","code":""},{"path":"https://AntoniKingston.github.io/gipsDA/reference/print.gipsmult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Printing gipsmult object — print.gipsmult","text":"Returns invisible NULL.","code":""},{"path":[]},{"path":"https://AntoniKingston.github.io/gipsDA/reference/print.gipsmult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Printing gipsmult object — print.gipsmult","text":"","code":"Ss <- list(matrix(c(1, 0.5, 0.5, 2), nrow = 2, byrow = TRUE), matrix(c(2, 1, 3, 7), nrow = 2, byrow = TRUE)) noo <- c(10,13) g <- gipsmult(S, noo, perm = \"(12)\") #> Error: object 'S' not found print(g, digits = 4, oneline = TRUE) #> Error: object 'g' not found"}]
